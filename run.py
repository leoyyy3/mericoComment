#!/usr/bin/env python3
"""
Merico ä»£ç è´¨é‡åˆ†æç³»ç»Ÿ - ç»Ÿä¸€å…¥å£

ä½¿ç”¨æ–¹æ³•:
    # å¯åŠ¨ Web æœåŠ¡
    python run.py serve --port 8080

    # è¿è¡Œåˆ†æ
    python run.py analyze --type all

    # ç”Ÿæˆå‘¨æŠ¥
    python run.py weekly --entity-id xxx --workspace-id xxx

    # å•ç‹¬è¿è¡Œåˆ†æå™¨
    python run.py data-analyze --file output/classified_results_xxx.json
"""

import argparse
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))


def cmd_serve(args):
    """å¯åŠ¨ Web æœåŠ¡"""
    from src.api import create_app

    app = create_app(args.config)

    print(f"ğŸš€ å¯åŠ¨æœåŠ¡: http://{args.host}:{args.port}")
    print(f"ğŸ“– API æ–‡æ¡£:")
    print(f"   - å¥åº·æ£€æŸ¥: GET  /api/health")
    print(f"   - æœåŠ¡çŠ¶æ€: GET  /api/status")
    print(f"   - åˆ†ææŠ¥å‘Š: GET  /api/analysis/reports")
    print(f"   - è¿è¡Œåˆ†æ: POST /api/analysis/all/run")
    print(f"   - ç”Ÿæˆå‘¨æŠ¥: POST /api/weekly-report/generate")

    app.run(host=args.host, port=args.port, debug=args.debug)


def cmd_analyze(args):
    """è¿è¡Œä»£ç åˆ†æ"""
    from config import ConfigLoader
    from src.services import AnalysisService

    # åŠ è½½é…ç½®
    loader = ConfigLoader(args.config)
    settings = loader.load()

    # åˆ›å»ºæœåŠ¡
    service = AnalysisService(settings)

    # è¿è¡Œåˆ†æ
    if args.type == 'all':
        result = service.run_all()
    elif args.type == 'uncommented':
        result = service.run_uncommented_analysis()
    elif args.type == 'duplicate':
        result = service.run_duplicate_analysis()
    else:
        print(f"æœªçŸ¥çš„åˆ†æç±»å‹: {args.type}")
        sys.exit(1)

    print(f"\nâœ… åˆ†æå®Œæˆ!")
    print(f"ç»“æœ: {result}")


def cmd_data_analyze(args):
    """åˆ†æå·²æœ‰æ•°æ®æ–‡ä»¶"""
    from src.core.analyzers import DataAnalyzer

    analyzer = DataAnalyzer(classified_file=args.file)
    analyzer.run_full_analysis()

    if args.export_csv:
        analyzer.export_csv()
    if args.export_html:
        analyzer.export_html()

    print(f"\nâœ… æ•°æ®åˆ†æå®Œæˆ!")


def cmd_weekly(args):
    """ç”Ÿæˆå‘¨æŠ¥"""
    from config import ConfigLoader
    from src.services import WeeklyReportService

    # åŠ è½½é…ç½®
    loader = ConfigLoader(args.config)
    settings = loader.load()

    # åˆ›å»ºæœåŠ¡
    service = WeeklyReportService(settings)

    # ç”Ÿæˆå‘¨æŠ¥
    result = service.generate(
        entity_id=args.entity_id,
        workspace_id=args.workspace_id,
        custom_prompt=args.prompt,
        save_to_file=not args.no_save
    )

    print(f"\nâœ… å‘¨æŠ¥ç”Ÿæˆå®Œæˆ!")
    if 'file_path' in result:
        print(f"æ–‡ä»¶è·¯å¾„: {result['file_path']}")

    if args.print_report:
        print(f"\n{'-' * 60}")
        print(result['report'])


def cmd_fetch_duplicate(args):
    """è·å–é‡å¤å‡½æ•°æ•°æ®"""
    from src.core.fetchers import DuplicateFunctionsFetcher

    with DuplicateFunctionsFetcher(config_file=args.config) as fetcher:
        fetcher.run()

    print(f"\nâœ… é‡å¤å‡½æ•°æ•°æ®è·å–å®Œæˆ!")


def main():
    parser = argparse.ArgumentParser(
        description='Merico ä»£ç è´¨é‡åˆ†æç³»ç»Ÿ',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument(
        '--config', '-c',
        type=str,
        default='config.json',
        help='é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config.json)'
    )

    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')

    # serve å‘½ä»¤
    serve_parser = subparsers.add_parser('serve', help='å¯åŠ¨ Web æœåŠ¡')
    serve_parser.add_argument('--host', default='0.0.0.0', help='ç»‘å®šåœ°å€')
    serve_parser.add_argument('--port', '-p', type=int, default=8080, help='ç«¯å£å·')
    serve_parser.add_argument('--debug', '-d', action='store_true', help='è°ƒè¯•æ¨¡å¼')
    serve_parser.set_defaults(func=cmd_serve)

    # analyze å‘½ä»¤
    analyze_parser = subparsers.add_parser('analyze', help='è¿è¡Œä»£ç åˆ†æ')
    analyze_parser.add_argument(
        '--type', '-t',
        choices=['all', 'uncommented', 'duplicate'],
        default='all',
        help='åˆ†æç±»å‹'
    )
    analyze_parser.set_defaults(func=cmd_analyze)

    # data-analyze å‘½ä»¤
    data_analyze_parser = subparsers.add_parser('data-analyze', help='åˆ†æå·²æœ‰æ•°æ®æ–‡ä»¶')
    data_analyze_parser.add_argument('--file', '-f', help='æ•°æ®æ–‡ä»¶è·¯å¾„')
    data_analyze_parser.add_argument('--export-csv', action='store_true', help='å¯¼å‡ºCSV')
    data_analyze_parser.add_argument('--export-html', action='store_true', help='å¯¼å‡ºHTML')
    data_analyze_parser.set_defaults(func=cmd_data_analyze)

    # weekly å‘½ä»¤
    weekly_parser = subparsers.add_parser('weekly', help='ç”Ÿæˆå‘¨æŠ¥')
    weekly_parser.add_argument('--entity-id', '-e', required=True, help='å®ä½“ ID')
    weekly_parser.add_argument('--workspace-id', '-w', required=True, help='å·¥ä½œç©ºé—´ ID')
    weekly_parser.add_argument('--prompt', '-P', help='è‡ªå®šä¹‰æç¤ºè¯')
    weekly_parser.add_argument('--no-save', action='store_true', help='ä¸ä¿å­˜åˆ°æ–‡ä»¶')
    weekly_parser.add_argument('--print-report', action='store_true', help='æ‰“å°å‘¨æŠ¥å†…å®¹')
    weekly_parser.set_defaults(func=cmd_weekly)

    # fetch-duplicate å‘½ä»¤
    fetch_dup_parser = subparsers.add_parser('fetch-duplicate', help='è·å–é‡å¤å‡½æ•°æ•°æ®')
    fetch_dup_parser.set_defaults(func=cmd_fetch_duplicate)

    args = parser.parse_args()

    if args.command is None:
        parser.print_help()
        sys.exit(0)

    args.func(args)


if __name__ == '__main__':
    main()
